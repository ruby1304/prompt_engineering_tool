import streamlit as st
import json
import time
import pandas as pd
import uuid
from typing import Dict, Any, List, Tuple, Optional

from config import load_template, get_template_list, load_test_set, get_test_set_list, save_test_set
from utils.common import render_prompt_template, format_chat_history, generate_dialogue_improvement_report
from models.api_clients import get_provider_from_model
from ui.components import (
    select_single_model, 
    show_evaluation_detail,
    display_dialogue_analysis
)
from utils.parallel_executor import execute_model_sync
from utils.evaluator import PromptEvaluator
from utils.test_set_manager import generate_unique_id, add_test_case


def render_prompt_dialogue_test():
    """æ¸²æŸ“æç¤ºè¯å¤šè½®å¯¹è¯æµ‹è¯•é¡µé¢"""
    st.title("ğŸ—£ï¸ æç¤ºè¯å¤šè½®å¯¹è¯æµ‹è¯•")
    
    st.markdown("""
    <div style="background-color: #f8f9fa; padding: 20px; border-radius: 10px; margin-bottom: 20px;">
    <h3 style="color: #4b778d;">å¤šè½®å¯¹è¯äº¤äº’æµ‹è¯•</h3>
    <p>æµ‹è¯•æŸä¸ªå¯¹è¯æç¤ºè¯åœ¨å¤šè½®å¯¹è¯ä¸­çš„æ•ˆæœï¼Œè¯„ä¼°æ¯è½®å¯¹è¯è´¨é‡ï¼Œå¹¶åˆ†ææ¨¡å‹å’Œæç¤ºè¯å¯èƒ½å­˜åœ¨çš„é—®é¢˜ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    # åˆå§‹åŒ–å¯¹è¯å†å²
    if "dialogue_history" not in st.session_state:
        st.session_state.dialogue_history = []
    
    if "chat_turn" not in st.session_state:
        st.session_state.chat_turn = 0
        
    if "evaluation_results" not in st.session_state:
        st.session_state.evaluation_results = []
    
    if "prompt_ratings" not in st.session_state:
        st.session_state.prompt_ratings = []
        
    # ç”¨äºè·Ÿè¸ªå½“å‰æŸ¥çœ‹çš„è¯„ä¼°è¯¦æƒ…ï¼ˆ-1è¡¨ç¤ºæœªæŸ¥çœ‹ä»»ä½•è¯„ä¼°ï¼‰
    if "current_eval_view" not in st.session_state:
        st.session_state.current_eval_view = -1
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼šå·¦ä¾§è®¾ç½®ï¼Œå³ä¾§å¯¹è¯
    col_config, col_chat = st.columns([3, 4])
    
    with col_config:
        st.subheader("å¯¹è¯è®¾ç½®")
        
        # é€‰æ‹©æç¤ºè¯æ¨¡æ¿
        st.write("#### é€‰æ‹©æç¤ºè¯æ¨¡æ¿")
        template_list = get_template_list()
        if not template_list:
            st.warning("æœªæ‰¾åˆ°æç¤ºè¯æ¨¡æ¿ï¼Œè¯·å…ˆåˆ›å»ºæ¨¡æ¿")
            return
            
        selected_template_name = st.selectbox(
            "é€‰æ‹©æ¨¡æ¿",
            options=template_list,
            help="é€‰æ‹©è¦æµ‹è¯•çš„æç¤ºè¯æ¨¡æ¿"
        )
        
        # åŠ è½½æ¨¡æ¿
        if selected_template_name:
            template = load_template(selected_template_name)
            if template:
                st.success(f"å·²åŠ è½½æ¨¡æ¿: {selected_template_name}")
                
                # å±•ç¤ºæ¨¡æ¿å†…å®¹é¢„è§ˆ
                with st.expander("æŸ¥çœ‹æ¨¡æ¿å†…å®¹", expanded=False):
                    st.code(template.get("template", ""))
                    st.write(f"**æè¿°:** {template.get('description', 'æ— æè¿°')}")
            else:
                st.error(f"æ— æ³•åŠ è½½æ¨¡æ¿ {selected_template_name}")
                return
        
        # é€‰æ‹©æ¨¡å‹
        st.write("#### é€‰æ‹©è¯­è¨€æ¨¡å‹")
        model, provider = select_single_model(key_prefix="dialogue_test", help_text="é€‰æ‹©ç”¨äºæµ‹è¯•çš„æ¨¡å‹")
        
        if not model:
            st.warning("è¯·é€‰æ‹©ä¸€ä¸ªæ¨¡å‹")
        
        # æ¨¡å‹å‚æ•°è®¾ç½®
        st.write("#### æ¨¡å‹å‚æ•°")
        temperature = st.slider("Temperature", 0.0, 2.0, 0.7, 0.1, 
                              help="æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ã€‚è¾ƒé«˜çš„å€¼ä¼šäº§ç”Ÿæ›´å¤šæ ·åŒ–ä½†å¯èƒ½ä¸ä¸€è‡´çš„è¾“å‡º")
        
        # ä¼šè¯æ§åˆ¶æŒ‰é’®
        st.write("#### ä¼šè¯æ§åˆ¶")
        control_cols = st.columns(2)
        
        with control_cols[0]:
            if st.button("ğŸ”„ é‡ç½®å¯¹è¯", use_container_width=True):
                # é‡ç½®å¯¹è¯å†å²
                st.session_state.dialogue_history = []
                st.session_state.chat_turn = 0
                st.session_state.evaluation_results = []
                st.session_state.prompt_ratings = []
                st.experimental_rerun()
                
        with control_cols[1]:
            if st.button("ğŸ“Š åˆ†æå¯¹è¯", use_container_width=True, disabled=len(st.session_state.dialogue_history) < 2):
                analyze_dialogue()
                
        # è¯„ä¼°è®¾ç½®
        st.write("#### è¯„ä¼°è®¾ç½®")
        auto_evaluate = st.checkbox("è‡ªåŠ¨è¯„ä¼°æ¯è½®å¯¹è¯", value=True, help="æ¯è½®å¯¹è¯åè‡ªåŠ¨è¿›è¡Œè¯„ä¼°")
        
        # ç›®æ ‡æµ‹è¯•é›†é€‰æ‹© - ç”¨äºä¿å­˜å¯¹è¯è½®æ¬¡
        st.write("#### ç›®æ ‡æµ‹è¯•é›†")
        test_set_list = get_test_set_list()
        if not test_set_list:
            st.warning("æœªæ‰¾åˆ°æµ‹è¯•é›†ï¼Œè¯·å…ˆåˆ›å»ºæµ‹è¯•é›†")
            selected_test_set = None
        else:
            selected_test_set = st.selectbox(
                "é€‰æ‹©æµ‹è¯•é›†",
                options=test_set_list,
                help="é€‰æ‹©è¦å°†å¯¹è¯è½®æ¬¡ä¿å­˜åˆ°çš„æµ‹è¯•é›†"
            )
            
            if selected_test_set:
                test_set = load_test_set(selected_test_set)
                if test_set:
                    st.success(f"å·²åŠ è½½æµ‹è¯•é›†: {selected_test_set}")
                    with st.expander("æµ‹è¯•é›†ä¿¡æ¯", expanded=False):
                        st.write(f"**æè¿°:** {test_set.get('description', 'æ— æè¿°')}")
                        st.write(f"**æ¡ˆä¾‹æ•°é‡:** {len(test_set.get('cases', []))}")
                else:
                    st.error(f"æ— æ³•åŠ è½½æµ‹è¯•é›† {selected_test_set}")
        
        # æ·»åŠ æç¤ºè¯è‡ªå®šä¹‰åŒºåŸŸï¼Œå¯é€‰å¡«
        st.write("#### æç¤ºè¯è‡ªå®šä¹‰å˜é‡")
        prompt_vars = {}
        with st.expander("è‡ªå®šä¹‰å˜é‡", expanded=False):
            var_keys = st.text_area(
                "å˜é‡ååˆ—è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", 
                help="è¾“å…¥è¦è‡ªå®šä¹‰çš„å˜é‡åï¼Œæ¯è¡Œä¸€ä¸ª"
            ).strip().split("\n")
            
            for key in var_keys:
                if key and key.strip():
                    prompt_vars[key.strip()] = st.text_input(f"å˜é‡ '{key.strip()}'", key=f"var_{key.strip()}")
        
    with col_chat:
        st.subheader("å¯¹è¯æµ‹è¯•")
        
        # å¯¹è¯å®¹å™¨
        chat_container = st.container(height=500, border=True)
        
        # æ¸²æŸ“å¯¹è¯å†å²
        with chat_container:
            if not st.session_state.dialogue_history:
                st.info("å¯¹è¯å°šæœªå¼€å§‹ã€‚è¯·åœ¨ä¸‹æ–¹è¾“å…¥æ‚¨çš„ç¬¬ä¸€æ¡æ¶ˆæ¯ã€‚")
            else:
                for i, exchange in enumerate(st.session_state.dialogue_history):
                    st.markdown(f"**ç”¨æˆ·:** {exchange['user']}")
                    
                    with st.chat_message("assistant", avatar="ğŸ¤–"):
                        st.markdown(exchange['assistant'])
                        
                        # å¦‚æœæœ‰è¯„ä¼°ç»“æœï¼Œæ˜¾ç¤ºç®€è¦è¯„åˆ†
                        if i < len(st.session_state.evaluation_results) and st.session_state.evaluation_results[i]:
                            eval_result = st.session_state.evaluation_results[i]
                            if "overall_score" in eval_result:
                                score = eval_result["overall_score"]
                                score_color = "green" if score >= 80 else "orange" if score >= 60 else "red"
                                st.markdown(f"<span style='color:{score_color};font-size:0.8em;'>å›å¤è´¨é‡è¯„åˆ†: {score}/100</span>", unsafe_allow_html=True)
                                
                                # æ˜¾ç¤ºè¯„ä¼°è¯¦æƒ…æŒ‰é’®å’Œä¿å­˜è½®æ¬¡æŒ‰é’®
                                cols = st.columns(2)
                                with cols[0]:
                                    # å¦‚æœå½“å‰æ­£åœ¨æŸ¥çœ‹è¿™ä¸ªè¯„ä¼°ï¼Œä¸æ˜¾ç¤ºæŸ¥çœ‹æŒ‰é’®
                                    if st.session_state.current_eval_view == i+1:
                                        # å·²ç»åœ¨æŸ¥çœ‹è¯¦æƒ…ä¸­ï¼Œæ˜¾ç¤ºè¯¦ç»†è¯„ä¼°å†…å®¹
                                        continue_viewing = show_evaluation_detail(eval_result, i+1)
                                        if not continue_viewing:
                                            st.session_state.current_eval_view = -1
                                            st.experimental_rerun()
                                    else:
                                        # å¦åˆ™æ˜¾ç¤ºæŸ¥çœ‹æŒ‰é’®
                                        if st.button(f"æŸ¥çœ‹è¯¦ç»†è¯„ä¼° #{i+1}", key=f"detail_eval_{i}", use_container_width=True):
                                            st.session_state.current_eval_view = i+1
                                            st.experimental_rerun()
                                
                                with cols[1]:
                                    if st.button(f"ä¿å­˜è½®æ¬¡ #{i+1}", key=f"save_turn_{i}", use_container_width=True):
                                        if selected_test_set:
                                            save_dialogue_turn_to_test_set(
                                                selected_test_set,
                                                i,
                                                st.session_state.dialogue_history,
                                                eval_result
                                            )
                                        else:
                                            st.error("è¯·å…ˆé€‰æ‹©ç›®æ ‡æµ‹è¯•é›†")
        
        # ç”¨æˆ·è¾“å…¥åŒº
        user_input = st.text_area("è¾“å…¥æ‚¨çš„æ¶ˆæ¯", key="user_msg_input", height=100, placeholder="æŒ‰ Shift+Enter æ¢è¡Œ", on_change=None)

        # æäº¤æŒ‰é’®å’Œå›è½¦é”®å…¼å®¹
        if st.button("å‘é€", type="primary", use_container_width=True) or st.session_state.get("enter_pressed", False):
            if not user_input:
                st.warning("è¯·è¾“å…¥æ¶ˆæ¯")
            elif not model:
                st.warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ¨¡å‹")
            elif not selected_template_name:
                st.warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæç¤ºè¯æ¨¡æ¿")
            else:
                with st.spinner("æ¨¡å‹æ€è€ƒä¸­..."):
                    # å‡†å¤‡å¯¹è¯å†å²ä»¥æ·»åŠ åˆ°æç¤ºè¯ä¸­
                    chat_records = format_chat_history(st.session_state.dialogue_history)

                    # å‡†å¤‡æ¨¡æ¿å˜é‡
                    template_vars = {
                        "chat_records": chat_records,
                        **prompt_vars  # æ·»åŠ ç”¨æˆ·è‡ªå®šä¹‰çš„å˜é‡
                    }

                    # æ¸²æŸ“æç¤ºè¯æ¨¡æ¿
                    prompt_template = render_prompt_template(template, {"variables": template_vars}, {"variables": {}})

                    # åˆ›å»ºæ¶ˆæ¯åˆ—è¡¨
                    messages = []

                    # æ·»åŠ ç³»ç»Ÿæç¤ºè¯
                    messages.append({"role": "system", "content": prompt_template})

                    # è°ƒç”¨æ¨¡å‹
                    params = {"temperature": temperature, "max_tokens": 8000}

                    # æ·»åŠ æ–°çš„ç”¨æˆ·æ¶ˆæ¯
                    messages.append({"role": "user", "content": user_input})

                    try:
                        # ä½¿ç”¨åŒæ­¥è°ƒç”¨
                        response = execute_model_sync(
                            model=model,
                            provider=provider,
                            messages=messages,
                            params=params
                        )

                        if "error" in response and response["error"]:
                            st.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {response['error']}")
                            return

                        # è·å–æ¨¡å‹å›å¤
                        assistant_response = response.get("text", "")

                        # æ›´æ–°å¯¹è¯å†å²
                        st.session_state.dialogue_history.append({
                            "user": user_input,
                            "assistant": assistant_response,
                            "model": model,
                            "turn": st.session_state.chat_turn + 1,
                            "timestamp": int(time.time()),
                            "prompt_template": prompt_template,
                            "usage": response.get("usage", {}),
                            "complete_messages": messages,
                            "chat_records": chat_records  # ä¿å­˜å½“å‰è½®æ¬¡çš„å¯¹è¯å†å²
                        })

                        # å¢åŠ å¯¹è¯å›åˆæ•°
                        st.session_state.chat_turn += 1

                        # å¦‚æœå¯ç”¨äº†è‡ªåŠ¨è¯„ä¼°ï¼Œè¯„ä¼°æ­¤è½®å¯¹è¯
                        if auto_evaluate:
                            # åˆ›å»ºè¯„ä¼°å™¨
                            evaluator = PromptEvaluator()
                            evaluation = evaluator.evaluate_dialogue_turn(
                                user_input, 
                                assistant_response, 
                                prompt_template,
                                st.session_state.chat_turn
                            )
                            st.session_state.evaluation_results.append(evaluation)

                            # ä¿å­˜æç¤ºè¯è¯„åˆ†è®°å½•
                            if "scores" in evaluation:
                                st.session_state.prompt_ratings.append({
                                    "turn": st.session_state.chat_turn,
                                    "scores": evaluation["scores"],
                                    "overall": evaluation["overall_score"]
                                })
                        else:
                            # å¦‚æœæœªå¯ç”¨è‡ªåŠ¨è¯„ä¼°ï¼Œæ·»åŠ ä¸€ä¸ªç©ºçš„å ä½ç¬¦
                            st.session_state.evaluation_results.append(None)

                        # æ¸…ç©ºè¾“å…¥æ¡† (é€šè¿‡é‡æ–°æ¸²æŸ“é¡µé¢å®ç°)
                        st.experimental_rerun()

                    except Exception as e:
                        st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")

        # ç›‘å¬å›è½¦é”®äº‹ä»¶
        st.session_state.enter_pressed = st.text_input("", key="hidden_input", on_change=lambda: st.session_state.update({"enter_pressed": True}))


def save_dialogue_turn_to_test_set(test_set_name: str, turn_index: int, dialogue_history: List[Dict], evaluation: Dict = None) -> None:
    """å°†æŒ‡å®šçš„å¯¹è¯è½®æ¬¡ä¿å­˜åˆ°æµ‹è¯•é›†ä¸­
    
    Args:
        test_set_name: æµ‹è¯•é›†åç§°
        turn_index: å¯¹è¯è½®æ¬¡ç´¢å¼•
        dialogue_history: å®Œæ•´å¯¹è¯å†å²
        evaluation: è¯„ä¼°ç»“æœï¼ˆå¯é€‰ï¼‰
    """
    if turn_index < 0 or turn_index >= len(dialogue_history):
        st.error(f"æ— æ•ˆçš„å¯¹è¯è½®æ¬¡ç´¢å¼•: {turn_index}")
        return
    
    # åŠ è½½ç›®æ ‡æµ‹è¯•é›†
    test_set = load_test_set(test_set_name)
    if not test_set:
        st.error(f"æ— æ³•åŠ è½½æµ‹è¯•é›† {test_set_name}")
        return
    
    # è·å–å½“å‰è½®æ¬¡å¯¹è¯
    turn_data = dialogue_history[turn_index]
    
    # è·å–å½“å‰è½®æ¬¡çš„å¯¹è¯å†å²ä¸Šä¸‹æ–‡
    chat_records = turn_data.get("chat_records", format_chat_history(dialogue_history[:turn_index]))
    
    # åˆ›å»ºæ–°çš„æµ‹è¯•ç”¨ä¾‹
    new_case = {
        "id": generate_unique_id(),
        "description": f"å¯¹è¯è½®æ¬¡ #{turn_index+1} - {time.strftime('%Y-%m-%d %H:%M:%S')}",
        "user_input": turn_data.get("user", ""),
        "expected_output": "",  # é»˜è®¤ä¸è®¾ç½®æœŸæœ›è¾“å‡º
        "model_response": turn_data.get("assistant", ""),  # ä¿å­˜æ¨¡å‹å®é™…å“åº”
        "evaluation_criteria": {
            "relevance": "æ¨¡å‹å“åº”ä¸ç”¨æˆ·æé—®çš„ç›¸å…³æ€§",
            "helpfulness": "æ¨¡å‹å“åº”å¯¹è§£å†³ç”¨æˆ·é—®é¢˜çš„å¸®åŠ©ç¨‹åº¦",
            "accuracy": "æ¨¡å‹å“åº”ä¸­ä¿¡æ¯çš„å‡†ç¡®æ€§",
            "prompt_following": "æ¨¡å‹éµå¾ªæç¤ºè¯æŒ‡ä»¤çš„ç¨‹åº¦",
            "consistency": "æ¨¡å‹å›å¤ä¸ä¹‹å‰å¯¹è¯çš„ä¸€è‡´æ€§",
            "coherence": "æ¨¡å‹å›å¤çš„è¿è´¯æ€§å’Œé€»è¾‘æ€§",
        },
        "variables": {
            "chat_records": chat_records,  # ä¿å­˜å¯¹è¯å†å²ä¸Šä¸‹æ–‡
            "model": turn_data.get("model", ""),
            "timestamp": turn_data.get("timestamp", int(time.time())),
        },
        "timestamp": int(time.time())
    }
    
    # å¦‚æœæœ‰è¯„ä¼°ç»“æœï¼Œä¹Ÿä¿å­˜ä¸‹æ¥
    if evaluation:
        new_case["evaluation"] = evaluation
    
    # æ·»åŠ åˆ°æµ‹è¯•é›†
    test_set = add_test_case(test_set, new_case)
    
    # ä¿å­˜æ›´æ–°çš„æµ‹è¯•é›†
    save_test_set(test_set_name, test_set)
    
    # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
    st.success(f"å·²å°†å¯¹è¯è½®æ¬¡ #{turn_index+1} ä¿å­˜åˆ°æµ‹è¯•é›† '{test_set_name}'")


def analyze_dialogue():
    """åˆ†æå¯¹è¯å¹¶æ˜¾ç¤ºç»“æœ"""
    if not st.session_state.dialogue_history or len(st.session_state.dialogue_history) < 2:
        st.warning("éœ€è¦è‡³å°‘ä¸¤è½®å¯¹è¯æ‰èƒ½è¿›è¡Œåˆ†æ")
        return
    
    # ä½¿ç”¨ç»„ä»¶æ˜¾ç¤ºå¯¹è¯åˆ†æ
    prompt_suggestions, model_suggestions = display_dialogue_analysis(
        st.session_state.dialogue_history,
        st.session_state.evaluation_results,
        st.session_state.prompt_ratings
    )
    
    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    if st.button("ç”Ÿæˆæ”¹è¿›æŠ¥å‘Š", use_container_width=True):
        with st.spinner("æ­£åœ¨ç”Ÿæˆæ”¹è¿›æŠ¥å‘Š..."):
            report = generate_dialogue_improvement_report(
                st.session_state.dialogue_history,
                st.session_state.evaluation_results
            )
            st.code(report, language="markdown")
            
            # æä¾›ä¸‹è½½é“¾æ¥
            st.download_button(
                label="ä¸‹è½½æŠ¥å‘Š",
                data=report,
                file_name=f"dialogue_analysis_{int(time.time())}.md",
                mime="text/markdown"
            )