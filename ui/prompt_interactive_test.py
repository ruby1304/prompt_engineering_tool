import streamlit as st
import json
import time
from typing import Dict, Any, List, Optional
import asyncio

from config import load_template, get_template_list, load_test_set, get_test_set_list, save_test_set
from utils.test_set_manager import generate_unique_id, add_test_case
from utils.common import render_prompt_template
from models.api_clients import get_provider_from_model, get_client
from ui.components import select_single_model
from utils.parallel_executor import execute_models_sync
from utils.evaluator import PromptEvaluator


def render_prompt_interactive_test():
    """æ¸²æŸ“æç¤ºè¯äº¤äº’æµ‹è¯•é¡µé¢"""
    st.title("ğŸ§ª æç¤ºè¯äº¤äº’æµ‹è¯•")
    
    # æ£€æŸ¥æ˜¯å¦ä»è‡ªåŠ¨ä¼˜åŒ–é¡µé¢è·³è½¬è¿‡æ¥ï¼Œéœ€è¦ä½¿ç”¨ä¸´æ—¶æ¨¡æ¿
    coming_from_auto_optimization = "from_auto_optimization" in st.session_state and st.session_state.from_auto_optimization
    has_temp_template = "temp_test_template" in st.session_state and st.session_state.temp_test_template is not None
    
    if coming_from_auto_optimization and has_temp_template:
        # ä½¿ç”¨ä»è‡ªåŠ¨ä¼˜åŒ–é¡µé¢ä¼ é€’è¿‡æ¥çš„ä¸´æ—¶æ¨¡æ¿
        template = st.session_state.temp_test_template
        model = st.session_state.temp_test_model
        provider = st.session_state.temp_test_provider
        
        st.info(f"æ­£åœ¨æµ‹è¯•è‡ªåŠ¨ä¼˜åŒ–ç”Ÿæˆçš„æç¤ºè¯: {template.get('name', '')}")
        
        # æ¸…é™¤è¿™äº›æ ‡è®°ï¼Œé¿å…ä¸‹æ¬¡åˆ·æ–°é¡µé¢ä¾ç„¶ä½¿ç”¨ä¸´æ—¶æ¨¡æ¿
        st.session_state.from_auto_optimization = False
        
        # åˆ›å»ºè¿”å›è‡ªåŠ¨ä¼˜åŒ–é¡µé¢çš„æŒ‰é’®
        if st.button("â†©ï¸ è¿”å›è‡ªåŠ¨ä¼˜åŒ–é¡µé¢"):
            st.session_state.page = "prompt_auto_optimization"
            st.rerun()
    else:
        # æ­£å¸¸æµç¨‹ï¼Œæ˜¾ç¤ºæ ‡å‡†ä»‹ç»
        st.markdown("""
        <div style="background-color: #f8f9fa; padding: 20px; border-radius: 10px; margin-bottom: 20px;">
        <h3 style="color: #4b778d;">åœ¨è¿™é‡Œäº¤äº’å¼æµ‹è¯•æç¤ºè¯æ¨¡æ¿</h3>
        <p>é€‰æ‹©æç¤ºè¯æ¨¡æ¿å’Œæ¨¡å‹ï¼Œè¾“å…¥è‡ªå®šä¹‰å†…å®¹ï¼ŒæŸ¥çœ‹æ¨¡å‹å›å¤ï¼Œå°†ç”¨æˆ·è¾“å…¥ä¿å­˜åˆ°æµ‹è¯•é›†ä¸­ã€‚</p>
        </div>
        """, unsafe_allow_html=True)
    
    # åˆ†æˆä¸¤åˆ—ï¼šå·¦ä¾§é€‰æ‹©åŒºåŸŸï¼Œå³ä¾§ç»“æœæ˜¾ç¤º
    col1, col2 = st.columns([3, 5])
    
    with col1:
        # å¦‚æœä¸æ˜¯ä»è‡ªåŠ¨ä¼˜åŒ–é¡µé¢è·³è½¬è¿‡æ¥ï¼Œæ˜¾ç¤ºæ­£å¸¸çš„æ¨¡æ¿é€‰æ‹©ç•Œé¢
        if not (coming_from_auto_optimization and has_temp_template):
            st.subheader("é€‰æ‹©æç¤ºè¯æ¨¡æ¿")
            # è·å–æ¨¡æ¿åˆ—è¡¨
            template_list = get_template_list()
            if not template_list:
                st.warning("æœªæ‰¾åˆ°æç¤ºè¯æ¨¡æ¿ï¼Œè¯·å…ˆåˆ›å»ºæ¨¡æ¿")
                return
                
            # é€‰æ‹©æ¨¡æ¿
            selected_template_name = st.selectbox(
                "é€‰æ‹©æ¨¡æ¿",
                options=template_list,
                help="é€‰æ‹©è¦æµ‹è¯•çš„æç¤ºè¯æ¨¡æ¿"
            )
            
            # åŠ è½½æ¨¡æ¿
            if selected_template_name:
                template = load_template(selected_template_name)
                if template:
                    st.success(f"å·²åŠ è½½æ¨¡æ¿: {selected_template_name}")
                    st.write(f"**æè¿°:** {template.get('description', 'æ— æè¿°')}")
                    
                    # å±•ç¤ºæ¨¡æ¿å†…å®¹é¢„è§ˆ
                    with st.expander("æŸ¥çœ‹æ¨¡æ¿å†…å®¹", expanded=False):
                        st.code(template.get("template", ""))
                else:
                    st.error(f"æ— æ³•åŠ è½½æ¨¡æ¿ {selected_template_name}")
                    return
            
            st.subheader("é€‰æ‹©æ¨¡å‹")
            # ä½¿ç”¨ç»„ä»¶é€‰æ‹©å•ä¸ªæ¨¡å‹
            model, provider = select_single_model(key_prefix="interactive_test", help_text="é€‰æ‹©ç”¨äºæµ‹è¯•çš„æ¨¡å‹")
        else:
            # å¦‚æœæ˜¯ä»è‡ªåŠ¨ä¼˜åŒ–é¡µé¢è·³è½¬è¿‡æ¥ï¼Œæ˜¾ç¤ºä¸´æ—¶æ¨¡æ¿ä¿¡æ¯
            st.subheader("ä¼˜åŒ–æç¤ºè¯è¯¦æƒ…")
            st.write(f"**åç§°:** {template.get('name', 'ä¼˜åŒ–æç¤ºè¯')}")
            st.write(f"**æè¿°:** {template.get('description', 'è‡ªåŠ¨ä¼˜åŒ–ç”Ÿæˆçš„æç¤ºè¯')}")
            
            # å±•ç¤ºæ¨¡æ¿å†…å®¹é¢„è§ˆ
            with st.expander("æŸ¥çœ‹æ¨¡æ¿å†…å®¹", expanded=True):
                st.code(template.get("template", ""))
            
            st.subheader("ä½¿ç”¨çš„æ¨¡å‹")
            st.write(f"**æ¨¡å‹:** {model} ({provider})")
        
        if not model:
            st.warning("è¯·é€‰æ‹©ä¸€ä¸ªæ¨¡å‹")
            return
            
        st.subheader("æµ‹è¯•å‚æ•°")
        temperature = st.slider("Temperature", 0.0, 2.0, 0.7, 0.1, 
                              help="æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ã€‚è¾ƒé«˜çš„å€¼ä¼šäº§ç”Ÿæ›´å¤šæ ·åŒ–ä½†å¯èƒ½ä¸ä¸€è‡´çš„è¾“å‡º")
        
        # æ·»åŠ æµ‹è¯•æ¬¡æ•°é€‰æ‹©
        test_count = st.number_input(
            "æµ‹è¯•æ¬¡æ•°", 
            min_value=1, 
            max_value=10, 
            value=1, 
            step=1,
            help="é€‰æ‹©è¦æ‰§è¡Œçš„æµ‹è¯•æ¬¡æ•°ï¼Œå¯ä»¥ä½¿ç”¨å¹¶è¡Œè°ƒç”¨è¿›è¡Œå¤šæ¬¡æµ‹è¯•"
        )
        
        # æ·»åŠ æ˜¯å¦ä½¿ç”¨å¹¶è¡Œè°ƒç”¨çš„é€‰é¡¹
        use_parallel = st.checkbox("ä½¿ç”¨å¹¶è¡Œè°ƒç”¨", value=True, help="å¹¶è¡Œæ‰§è¡Œå¤šæ¬¡æµ‹è¯•ä»¥æé«˜æ•ˆç‡")
        
        # æ·»åŠ ç”¨æˆ·è¾“å…¥åŒºåŸŸ
        st.subheader("ç”¨æˆ·è¾“å…¥")
        user_input = st.text_area(
            "åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„æµ‹è¯•å†…å®¹",
            height=200,
            help="è¾“å…¥æ‚¨æƒ³è¦æµ‹è¯•çš„å†…å®¹"
        )
        
        # åªæœ‰åœ¨æ™®é€šæ¨¡å¼ä¸‹æ‰æ˜¾ç¤ºç›®æ ‡æµ‹è¯•é›†é€‰æ‹©
        if not (coming_from_auto_optimization and has_temp_template):
            st.subheader("ç›®æ ‡æµ‹è¯•é›†")
            test_set_list = get_test_set_list()
            if not test_set_list:
                st.warning("æœªæ‰¾åˆ°æµ‹è¯•é›†ï¼Œè¯·å…ˆåˆ›å»ºæµ‹è¯•é›†")
                selected_test_set = None
            else:
                selected_test_set = st.selectbox(
                    "é€‰æ‹©æµ‹è¯•é›†",
                    options=test_set_list,
                    help="é€‰æ‹©è¦å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°çš„æµ‹è¯•é›†"
                )
                
                if selected_test_set:
                    test_set = load_test_set(selected_test_set)
                    if test_set:
                        st.success(f"å·²åŠ è½½æµ‹è¯•é›†: {selected_test_set}")
                        with st.expander("æµ‹è¯•é›†ä¿¡æ¯", expanded=False):
                            st.write(f"**æè¿°:** {test_set.get('description', 'æ— æè¿°')}")
                            st.write(f"**æ¡ˆä¾‹æ•°é‡:** {len(test_set.get('cases', []))}")
                    else:
                        st.error(f"æ— æ³•åŠ è½½æµ‹è¯•é›† {selected_test_set}")
                        return
        else:
            # ä»è‡ªåŠ¨ä¼˜åŒ–é¡µé¢è·³è½¬è¿‡æ¥æ—¶ä¸éœ€è¦é€‰æ‹©æµ‹è¯•é›†
            selected_test_set = None
        
        # è¿è¡Œæµ‹è¯•æŒ‰é’®
        run_btn = st.button("â–¶ï¸ è¿è¡Œæµ‹è¯•", type="primary")
    
    with col2:
        st.subheader("æµ‹è¯•ç»“æœ")
        
        # ç¬¬ä¸€æ¬¡è®¿é—®é¡µé¢æ—¶åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        if "test_results" not in st.session_state:
            st.session_state.test_results = []
        if "user_input" not in st.session_state:
            st.session_state.user_input = ""
        if "evaluation_results" not in st.session_state:
            st.session_state.evaluation_results = {}
        
        if run_btn:
            if not user_input:
                st.error("è¯·è¾“å…¥æµ‹è¯•å†…å®¹")
                return
                
            if not template:
                st.error("è¯·é€‰æ‹©æç¤ºè¯æ¨¡æ¿")
                return
                
            if not model:
                st.error("è¯·é€‰æ‹©æ¨¡å‹")
                return
                
            with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {model} è¿›è¡Œ {test_count} æ¬¡æµ‹è¯•" + ("ï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰" if use_parallel else "")):
                try:
                    # æ¸²æŸ“æç¤ºè¯æ¨¡æ¿
                    prompt_template = render_prompt_template(template, {"variables": {}}, {"variables": {}})
                    
                    # è®¾ç½®å‚æ•°
                    params = {"temperature": temperature, "max_tokens": 1000}
                    
                    if test_count == 1 or not use_parallel:
                        # å•æ¬¡æµ‹è¯•æˆ–ä¸²è¡Œæ‰§è¡Œå¤šæ¬¡æµ‹è¯•
                        results = []
                        for i in range(test_count):
                            # åˆ›å»ºäº‹ä»¶å¾ªç¯
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                            
                            # è·å–APIå®¢æˆ·ç«¯
                            client = get_client(provider)
                            
                            # è°ƒç”¨æ¨¡å‹
                            messages = [
                                {"role": "system", "content": prompt_template},
                                {"role": "user", "content": user_input}
                            ]
                            response = loop.run_until_complete(client.generate_with_messages(
                                messages,
                                model,
                                params
                            ))
                            
                            # å…³é—­å¾ªç¯
                            loop.close()
                            
                            # ä¿å­˜ç»“æœ
                            if "error" in response and response["error"]:
                                results.append({
                                    "error": response["error"],
                                    "model_response": f"é”™è¯¯ï¼š{response['error']}"
                                })
                            else:
                                results.append({
                                    "model_response": response.get("text", ""),
                                    "usage": response.get("usage", {})
                                })
                    else:
                        # å¹¶è¡Œæ‰§è¡Œå¤šæ¬¡æµ‹è¯•
                        # å‡†å¤‡å¤šä¸ªè¯·æ±‚
                        requests = []
                        for i in range(test_count):
                            messages = [
                                {"role": "system", "content": prompt_template},
                                {"role": "user", "content": user_input}
                            ]
                            requests.append({
                                "model": model,
                                "messages": messages,
                                "provider": provider,
                                "params": params
                            })
                        
                        # ä½¿ç”¨å¹¶è¡Œæ‰§è¡Œå™¨æ‰§è¡Œè¯·æ±‚
                        responses = execute_models_sync(requests)
                        
                        # å¤„ç†æ‰€æœ‰å“åº”
                        results = []
                        for response in responses:
                            if "error" in response and response["error"]:
                                results.append({
                                    "error": response["error"],
                                    "model_response": f"é”™è¯¯ï¼š{response['error']}"
                                })
                            else:
                                results.append({
                                    "model_response": response.get("text", ""),
                                    "usage": response.get("usage", {})
                                })
                    
                    # ä¿å­˜ç»“æœåˆ°ä¼šè¯çŠ¶æ€ï¼Œä¸æ‰§è¡Œè¯„ä¼°
                    st.session_state.test_results = [
                        {
                            "id": f"result_{i}_{int(time.time())}",  # æ·»åŠ å”¯ä¸€IDç”¨äºåç»­è¯„ä¼°
                            "template": template,
                            "model": model,
                            "user_input": user_input,
                            "prompt_template": prompt_template,
                            "model_response": result.get("model_response", ""),
                            "usage": result.get("usage", {})
                        }
                        for i, result in enumerate(results)
                    ]
                    st.session_state.user_input = user_input
                    # æ¸…ç©ºä¹‹å‰çš„è¯„ä¼°ç»“æœ
                    st.session_state.evaluation_results = {}
                    
                except Exception as e:
                    st.error(f"æµ‹è¯•å¤±è´¥: {str(e)}")
                    return
        
        # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
        if st.session_state.test_results:
            user_input = st.session_state.user_input
            
            # åˆ›å»ºä¸€ä¸ªé¡¶éƒ¨æ“ä½œæ ï¼ŒåŒ…å«ä¿å­˜å’Œæ¸…é™¤æŒ‰é’®
            action_col1, action_col2, action_col3 = st.columns([5, 2, 2])
            
            with action_col1:
                st.write("### ç”¨æˆ·è¾“å…¥:")
                st.code(user_input)
            
            # ç»Ÿä¸€çš„ä¿å­˜ç”¨æˆ·è¾“å…¥æŒ‰é’® - åªæœ‰éè‡ªåŠ¨ä¼˜åŒ–ä¸´æ—¶æ¨¡æ¿æ¨¡å¼æ‰æ˜¾ç¤º
            if not (coming_from_auto_optimization and has_temp_template):
                with action_col2:
                    if st.button("ğŸ’¾ ä¿å­˜ç”¨æˆ·è¾“å…¥", use_container_width=True):
                        if not selected_test_set:
                            st.error("è¯·é€‰æ‹©ç›®æ ‡æµ‹è¯•é›†")
                        else:
                            # åŠ è½½æµ‹è¯•é›†
                            test_set = load_test_set(selected_test_set)
                            if not test_set:
                                st.error(f"æ— æ³•åŠ è½½æµ‹è¯•é›† {selected_test_set}")
                            else:
                                # åˆ›å»ºæ–°çš„æµ‹è¯•ç”¨ä¾‹ï¼ŒåªåŒ…å«ç”¨æˆ·è¾“å…¥ï¼Œä¸åŒ…å«æ¨¡å‹è¾“å‡º
                                new_case = {
                                    "id": generate_unique_id(),
                                    "description": f"{template.get('name', '')}ç”¨æˆ·è¾“å…¥",
                                    "user_input": user_input,
                                    "expected_output": "",  # ä¸è®¾ç½®æœŸæœ›è¾“å‡º
                                    "evaluation_criteria": {
                                        "accuracy": "è¯„ä¼°å›ç­”çš„å‡†ç¡®æ€§",
                                        "completeness": "è¯„ä¼°å›ç­”çš„å®Œæ•´æ€§",
                                        "relevance": "è¯„ä¼°å›ç­”çš„ç›¸å…³æ€§",
                                        "clarity": "è¯„ä¼°å›ç­”çš„æ¸…æ™°åº¦"
                                    },
                                    "variables": {},
                                    "timestamp": int(time.time())
                                }
                                
                                # æ·»åŠ åˆ°æµ‹è¯•é›†
                                test_set = add_test_case(test_set, new_case)
                                
                                # ä¿å­˜æ›´æ–°çš„æµ‹è¯•é›†
                                save_test_set(selected_test_set, test_set)
                                
                                st.success(f"ç”¨æˆ·è¾“å…¥å·²ä¿å­˜åˆ°æµ‹è¯•é›† '{selected_test_set}'")
            
            # æ¸…é™¤ç»“æœæŒ‰é’®
            with action_col3:
                if st.button("ğŸ”„ æ¸…é™¤ç»“æœ", use_container_width=True):
                    # æ¸…ç©ºæµ‹è¯•ç»“æœ
                    st.session_state.test_results = []
                    st.session_state.user_input = ""
                    st.session_state.evaluation_results = {}
                    st.experimental_rerun()
            
            # ä½¿ç”¨é€‰é¡¹å¡å±•ç¤ºå¤šä¸ªæ¨¡å‹å›å¤ï¼Œæé«˜å¸ƒå±€æ•ˆç‡
            if len(st.session_state.test_results) > 1:
                tabs = st.tabs([f"å›å¤ {i+1}" for i in range(len(st.session_state.test_results))])
                for i, (tab, result) in enumerate(zip(tabs, st.session_state.test_results)):
                    result_id = result["id"]
                    
                    with tab:
                        # æ¨¡å‹å›å¤
                        st.write("#### æ¨¡å‹å›å¤:")
                        st.code(result["model_response"])
                        
                        # æ·»åŠ ç‹¬ç«‹çš„è¯„ä¼°æŒ‰é’®
                        if st.button(f"ğŸ“Š è¯„ä¼°æ­¤å“åº”", key=f"evaluate_{result_id}"):
                            with st.spinner("æ­£åœ¨è¯„ä¼°æ¨¡å‹å“åº”..."):
                                evaluation = evaluate_model_response(result)
                                st.session_state.evaluation_results[result_id] = evaluation
                                st.experimental_rerun()  # é‡æ–°åŠ è½½ä»¥æ˜¾ç¤ºè¯„ä¼°ç»“æœ
                        
                        # å¦‚æœæœ‰è¯„ä¼°ç»“æœï¼Œæ˜¾ç¤ºè¯„ä¼°ç»“æœ
                        if result_id in st.session_state.evaluation_results:
                            display_evaluation_result(st.session_state.evaluation_results[result_id])
                        
                        # æ˜¾ç¤ºTokenä½¿ç”¨æƒ…å†µ
                        usage = result.get("usage", {})
                        if usage:
                            with st.expander("Token ä½¿ç”¨æƒ…å†µ", expanded=False):
                                st.json(usage)
            else:
                # å•ä¸ªç»“æœç›´æ¥æ˜¾ç¤º
                result = st.session_state.test_results[0]
                result_id = result["id"]
                
                # æ¨¡å‹å›å¤
                st.write("### æ¨¡å‹å›å¤:")
                st.code(result["model_response"])
                
                # æ·»åŠ ç‹¬ç«‹çš„è¯„ä¼°æŒ‰é’®
                if st.button(f"ğŸ“Š è¯„ä¼°æ­¤å“åº”", key=f"evaluate_{result_id}"):
                    with st.spinner("æ­£åœ¨è¯„ä¼°æ¨¡å‹å“åº”..."):
                        evaluation = evaluate_model_response(result)
                        st.session_state.evaluation_results[result_id] = evaluation
                        st.experimental_rerun()  # é‡æ–°åŠ è½½ä»¥æ˜¾ç¤ºè¯„ä¼°ç»“æœ
                
                # å¦‚æœæœ‰è¯„ä¼°ç»“æœï¼Œæ˜¾ç¤ºè¯„ä¼°ç»“æœ
                if result_id in st.session_state.evaluation_results:
                    display_evaluation_result(st.session_state.evaluation_results[result_id])
                
                # æ˜¾ç¤ºTokenä½¿ç”¨æƒ…å†µ
                usage = result.get("usage", {})
                if usage:
                    with st.expander("Token ä½¿ç”¨æƒ…å†µ", expanded=False):
                        st.json(usage)
                
                # å¦‚æœæ˜¯ä»è‡ªåŠ¨ä¼˜åŒ–é¡µé¢è·³è½¬è¿‡æ¥ï¼Œæ·»åŠ åé¦ˆæŒ‰é’®
                if coming_from_auto_optimization and has_temp_template:
                    st.subheader("åé¦ˆ")
                    user_feedback = st.text_area(
                        "æ‚¨å¯¹è¿™ä¸ªä¼˜åŒ–æç¤ºè¯çš„åé¦ˆ (å¯é€‰)",
                        placeholder="è¯·è¾“å…¥æ‚¨çš„åé¦ˆï¼Œä¾‹å¦‚ï¼šè¿™ä¸ªæç¤ºè¯æ•ˆæœå¾ˆå¥½ï¼Œä½†å¯ä»¥åœ¨...æ–¹é¢æ”¹è¿›",
                        height=100
                    )
                    
                    feedback_col1, feedback_col2 = st.columns(2)
                    with feedback_col1:
                        if st.button("ğŸ‘ å¾ˆå¥½ï¼Œç»§ç»­ä½¿ç”¨æ­¤æç¤ºè¯", type="primary"):
                            st.session_state.auto_optimization_feedback = {"type": "positive", "text": user_feedback}
                            st.session_state.page = "prompt_auto_optimization"
                            st.rerun()
                    
                    with feedback_col2:
                        if st.button("ğŸ‘ éœ€è¦æ”¹è¿›"):
                            st.session_state.auto_optimization_feedback = {"type": "negative", "text": user_feedback}
                            st.session_state.page = "prompt_auto_optimization"
                            st.rerun()
        else:
            st.info("è¿è¡Œæµ‹è¯•ä»¥æŸ¥çœ‹æ¨¡å‹å›å¤")


def evaluate_model_response(result: Dict) -> Dict:
    """è¯„ä¼°æ¨¡å‹å“åº”ä¸æç¤ºè¯çš„åŒ¹é…ç¨‹åº¦"""
    evaluator = PromptEvaluator()
    
    # æå–æ‰€éœ€æ•°æ®
    model_response = result.get("model_response", "")
    prompt_template = result.get("prompt_template", "")
    user_input = result.get("user_input", "")
    
    # è¯„ä¼°æ ‡å‡†
    evaluation_criteria = {
        "accuracy": "æ¨¡å‹å“åº”æ˜¯å¦å‡†ç¡®æ»¡è¶³ç”¨æˆ·éœ€æ±‚",
        "completeness": "æ¨¡å‹å“åº”æ˜¯å¦å®Œæ•´å›ç­”äº†ç”¨æˆ·é—®é¢˜",
        "relevance": "æ¨¡å‹å“åº”æ˜¯å¦ä¸ç”¨æˆ·é—®é¢˜ç›¸å…³",
        "clarity": "æ¨¡å‹å“åº”æ˜¯å¦æ¸…æ™°æ˜“æ‡‚",
        "instruction_following": "æ¨¡å‹æ˜¯å¦éµå¾ªäº†æç¤ºè¯ä¸­çš„æŒ‡ä»¤"
    }
    
    # åˆ›å»ºä¸€ä¸ªæœŸæœ›è¾“å‡ºï¼Œç”¨äºè¯„ä¼°
    # åœ¨äº¤äº’å¼æµ‹è¯•ä¸­æˆ‘ä»¬æ²¡æœ‰å®é™…çš„æœŸæœ›è¾“å‡ºï¼Œæ‰€ä»¥ä½¿ç”¨ä¸€ä¸ªé€šç”¨è¯´æ˜
    expected_output = "æ ¹æ®æç¤ºè¯è¦æ±‚ï¼Œç»™å‡ºæ°å½“çš„å›ç­”"
    
    # æ‰§è¡Œè¯„ä¼°
    return evaluator.evaluate_response_sync(
        model_response,
        expected_output,
        evaluation_criteria,
        prompt_template + "\nç”¨æˆ·: " + user_input
    )


def display_evaluation_result(evaluation: Dict):
    """å±•ç¤ºè¯„ä¼°ç»“æœ"""
    st.write("#### å“åº”è¯„ä¼°ç»“æœ:")
    
    # å¦‚æœæœ‰é”™è¯¯ä¿¡æ¯ï¼Œæ˜¾ç¤ºé”™è¯¯
    if "error" in evaluation:
        st.warning(f"è¯„ä¼°è¿‡ç¨‹é‡åˆ°é—®é¢˜: {evaluation.get('error')}")
        return
    
    # æ˜¾ç¤ºåˆ†æ•°
    if "scores" in evaluation:
        scores = evaluation["scores"]
        
        # åˆ›å»ºä¸¤è¡Œè¯„åˆ†ï¼Œæ¯è¡Œæ˜¾ç¤ºä¸‰ä¸ªæŒ‡æ ‡
        row1_cols = st.columns(3)
        with row1_cols[0]:
            st.metric("å‡†ç¡®æ€§", f"{scores.get('accuracy', 0)}åˆ†")
        with row1_cols[1]:
            st.metric("å®Œæ•´æ€§", f"{scores.get('completeness', 0)}åˆ†")
        with row1_cols[2]:
            st.metric("ç›¸å…³æ€§", f"{scores.get('relevance', 0)}åˆ†")
        
        row2_cols = st.columns(3)
        with row2_cols[0]:
            st.metric("æ¸…æ™°åº¦", f"{scores.get('clarity', 0)}åˆ†")
        with row2_cols[1]:
            st.metric("æŒ‡ä»¤éµå¾ª", f"{scores.get('instruction_following', 0)}åˆ†")
        with row2_cols[2]:
            st.metric("æ€»ä½“è¯„åˆ†", f"{evaluation.get('overall_score', 0)}åˆ†")
        
        # æ˜¾ç¤ºè¯„ä¼°æ€»ç»“
        if "summary" in evaluation:
            st.write("**è¯„ä¼°æ€»ç»“:**")
            st.info(evaluation["summary"])
        
        # è¯¦ç»†åˆ†æ
        if "analysis" in evaluation:
            with st.expander("æŸ¥çœ‹è¯¦ç»†åˆ†æ", expanded=False):
                st.write(evaluation["analysis"])