import streamlit as st
from config import get_available_models, load_provider_config, get_provider_list

def render_model_selector():
    """æ¸²æŸ“æ¨¡å‹é€‰æ‹©ç•Œé¢"""
    st.title("ğŸ¤– æ¨¡å‹é€‰æ‹©")
    
    available_models = get_available_models()
    provider_list = get_provider_list()
    
    st.info("""
    åœ¨è¿™é‡ŒæŸ¥çœ‹å’Œç®¡ç†å¯ç”¨çš„æ¨¡å‹ã€‚æ‚¨å¯ä»¥è®¾ç½®åå¥½çš„è¯„ä¼°æ¨¡å‹ï¼Œå¹¶æŸ¥çœ‹å„æ¨¡å‹çš„èƒ½åŠ›å’Œä»·æ ¼ä¿¡æ¯ã€‚
    """)
    
    # åˆ›å»ºæä¾›å•†é€‰é¡¹å¡
    tabs = st.tabs(provider_list)
    
    for i, provider in enumerate(provider_list):
        with tabs[i]:
            st.subheader(f"{provider.capitalize()}æ¨¡å‹")
            
            models = available_models.get(provider, [])
            
            if not models:
                st.warning(f"æœªæ‰¾åˆ°{provider}æ¨¡å‹é…ç½®")
            else:
                # è·å–æä¾›å•†é…ç½®
                provider_config = load_provider_config(provider)
                is_custom = "custom_providers" in st.session_state and provider in st.session_state.custom_providers
                
                # å¦‚æœæ˜¯è‡ªå®šä¹‰æä¾›å•†ï¼Œæ˜¾ç¤ºé…ç½®ä¿¡æ¯
                if is_custom:
                    st.info(f"""
                    **æä¾›å•†ä¿¡æ¯**:
                    - æ˜¾ç¤ºåç§°: {provider_config.get('display_name', provider.capitalize())}
                    - APIåŸºç¡€URL: {provider_config.get('base_url', 'æœªè®¾ç½®')}
                    - APIç±»å‹: {provider_config.get('api_type', 'http')}
                    - æ¶ˆæ¯æ ¼å¼: {provider_config.get('message_format', 'openai')}
                    """)
                
                # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
                for model in models:
                    with st.expander(f"{model}"):
                        # å°è¯•è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯ - ä»é…ç½®æˆ–é¢„å®šä¹‰ä¿¡æ¯
                        display_model_info(provider, model)
    
    # è¯„ä¼°æ¨¡å‹è®¾ç½®
    st.divider()
    st.subheader("è¯„ä¼°æ¨¡å‹è®¾ç½®")
    
    # è·å–å½“å‰é…ç½®
    from config import load_config, save_config
    
    config = load_config()
    current_evaluator = config.get("evaluator_model", "gpt-4")
    
    # åˆ›å»ºæ‰€æœ‰å¯ç”¨æ¨¡å‹çš„åˆ—è¡¨
    all_models = []
    for provider, models in available_models.items():
        for model in models:
            all_models.append(f"{model} ({provider})")
    
    # æŸ¥æ‰¾å½“å‰è¯„ä¼°æ¨¡å‹çš„ç´¢å¼•
    current_index = 0
    for i, model_str in enumerate(all_models):
        if model_str.startswith(current_evaluator + " "):
            current_index = i
            break
    
    new_evaluator_str = st.selectbox(
        "é€‰æ‹©è¯„ä¼°æ¨¡å‹",
        all_models,
        index=current_index if current_index < len(all_models) else 0,
        help="è¯„ä¼°æ¨¡å‹ç”¨äºè¯„ä¼°ç”Ÿæˆç»“æœçš„è´¨é‡"
    )
    
    # ä»æ˜¾ç¤ºå­—ç¬¦ä¸²ä¸­æå–æ¨¡å‹åç§°
    if new_evaluator_str:
        new_evaluator = new_evaluator_str.split(" (")[0]
        
        if st.button("ä¿å­˜è¯„ä¼°æ¨¡å‹è®¾ç½®"):
            config["evaluator_model"] = new_evaluator
            save_config(config)
            st.success(f"è¯„ä¼°æ¨¡å‹å·²è®¾ç½®ä¸º: {new_evaluator}")
    
    # æ·»åŠ æœ¬åœ°è¯„ä¼°å¼€å…³
    use_local = config.get("use_local_evaluation", False)
    new_use_local = st.checkbox(
        "ä½¿ç”¨æœ¬åœ°è¯„ä¼°ï¼ˆä¸è°ƒç”¨APIï¼‰", 
        value=use_local,
        help="é€‰ä¸­æ­¤é¡¹å°†ä½¿ç”¨æœ¬åœ°è¯„ä¼°æ–¹æ³•ï¼Œè€Œä¸è°ƒç”¨è¯„ä¼°æ¨¡å‹API"
    )
    
    if new_use_local != use_local:
        config["use_local_evaluation"] = new_use_local
        save_config(config)
        st.success(f"æœ¬åœ°è¯„ä¼°è®¾ç½®å·²æ›´æ–°: {'å¯ç”¨' if new_use_local else 'ç¦ç”¨'}")

def display_model_info(provider, model):
    """æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯"""
    # è·å–æä¾›å•†é…ç½®
    provider_config = load_provider_config(provider)
    
    # é¢„å®šä¹‰æ¨¡å‹ä¿¡æ¯
    predefined_models = {
        "gpt-3.5-turbo": {
            "capability": "è‰¯å¥½çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œé€‚åˆä¸€èˆ¬æ€§ä»»åŠ¡",
            "context_window": "16K tokens",
            "price": "$0.0005 / 1K tokens (è¾“å…¥), $0.0015 / 1K tokens (è¾“å‡º)",
            "advantages": "ä»·æ ¼ä½å»‰ï¼Œå“åº”é€Ÿåº¦å¿«",
            "limitations": "å¤æ‚æ¨ç†èƒ½åŠ›è¾ƒå¼±ï¼ŒçŸ¥è¯†æˆªæ­¢æ—¥æœŸè¾ƒæ—©"
        },
        "gpt-4": {
            "capability": "å¾ˆå¼ºçš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œé€‚åˆå¤æ‚ä»»åŠ¡",
            "context_window": "8K tokens",
            "price": "$0.03 / 1K tokens (è¾“å…¥), $0.06 / 1K tokens (è¾“å‡º)",
            "advantages": "è¾ƒå¼ºçš„æ¨ç†èƒ½åŠ›ï¼Œæ›´å¥½çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›",
            "limitations": "ä»·æ ¼è¾ƒé«˜ï¼Œå“åº”é€Ÿåº¦è¾ƒæ…¢"
        },
    }
    
    # å¦‚æœæ˜¯é¢„å®šä¹‰æ¨¡å‹ï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    if model in predefined_models:
        model_info = predefined_models[model]
        st.write(f"""
        ### {model}
        - **èƒ½åŠ›**: {model_info['capability']}
        - **ä¸Šä¸‹æ–‡çª—å£**: {model_info['context_window']}
        - **ä»·æ ¼**: {model_info['price']}
        - **ä¼˜åŠ¿**: {model_info['advantages']}
        - **å±€é™**: {model_info['limitations']}
        """)
    else:
        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        price_input = provider_config.get("price_input", 0)
        price_output = provider_config.get("price_output", 0)
        
        st.write(f"""
        ### {model}
        - **æä¾›å•†**: {provider_config.get('display_name', provider.capitalize())}
        - **ä»·æ ¼**: ${price_input:.6f} / 1K tokens (è¾“å…¥), ${price_output:.6f} / 1K tokens (è¾“å‡º)
        """)

if __name__ == "__main__":
    render_model_selector()
