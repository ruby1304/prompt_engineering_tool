import streamlit as st
import json
import pandas as pd
import asyncio
from datetime import datetime
import time
import plotly.express as px
import plotly.graph_objects as go

from config import load_test_set, save_template
from utils.common import (
    calculate_average_score, 
    get_dimension_scores, 
    create_dimension_radar_chart,
    run_test,
    display_template_info,
    save_optimized_template,
    compare_dimension_performance
)
from ui.components import (
    display_test_summary,
    display_response_tabs,
    display_evaluation_results,
    display_test_case_details
)

def render_prompt_ab_test():
    st.title("ğŸ”¬ æç¤ºè¯A/Bæµ‹è¯•")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰A/Bæµ‹è¯•æ•°æ®
    if (not hasattr(st.session_state, 'ab_test_original') or 
        not hasattr(st.session_state, 'ab_test_optimized')):
        st.warning("è¯·å…ˆä»æç¤ºè¯ä¸“é¡¹ä¼˜åŒ–é¡µé¢å¯åŠ¨A/Bæµ‹è¯•")
        
        if st.button("è¿”å›æç¤ºè¯ä¸“é¡¹ä¼˜åŒ–"):
            st.session_state.page = "prompt_optimization"
            st.rerun()
        return
    
    # è·å–A/Bæµ‹è¯•æ•°æ®
    original_template = st.session_state.ab_test_original
    optimized_template = st.session_state.ab_test_optimized
    model = st.session_state.ab_test_model
    model_provider = st.session_state.get("ab_test_model_provider")
    test_set_name = st.session_state.ab_test_test_set
    
    st.markdown(f"""
    ### A/Bæµ‹è¯•: åŸå§‹æç¤ºè¯ vs ä¼˜åŒ–æç¤ºè¯
    
    - **æ¨¡å‹**: {model} ({model_provider if model_provider else "æœªæŒ‡å®šæä¾›å•†"})
    - **æµ‹è¯•é›†**: {test_set_name}
    """)
    
    # æ˜¾ç¤ºæç¤ºè¯å¯¹æ¯”
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("åŸå§‹æç¤ºè¯")
        display_template_info(original_template)
    
    with col2:
        st.subheader("ä¼˜åŒ–æç¤ºè¯")
        display_template_info(optimized_template)
    
    # æµ‹è¯•å‚æ•°è®¾ç½®
    st.subheader("æµ‹è¯•å‚æ•°")
    
    col1, col2 = st.columns(2)
    
    with col1:
        repeat_count = st.slider(
            "æ¯ä¸ªæµ‹è¯•é‡å¤æ¬¡æ•°", 
            min_value=1, 
            max_value=5, 
            value=2, 
            help="å¢åŠ é‡å¤æ¬¡æ•°å¯æé«˜ç»“æœç¨³å®šæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜æ¸©åº¦è®¾ç½®ä¸‹"
        )
    
    with col2:
        temperature = st.slider(
            "Temperature", 
            min_value=0.0, 
            max_value=2.0, 
            value=0.7, 
            step=0.1,
            help="æ§åˆ¶æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§ã€‚è¾ƒé«˜çš„å€¼ä¼šäº§ç”Ÿæ›´å¤šæ ·åŒ–ä½†å¯èƒ½ä¸ä¸€è‡´çš„è¾“å‡º"
        )
    
    # è¿è¡ŒA/Bæµ‹è¯•
    if "ab_test_results" not in st.session_state:
        if st.button("â–¶ï¸ è¿è¡ŒA/Bæµ‹è¯•", type="primary"):
            # åŠ è½½æµ‹è¯•é›†
            test_set = load_test_set(test_set_name)
            
            if not test_set or not test_set.get("cases"):
                st.error(f"æ— æ³•åŠ è½½æµ‹è¯•é›† '{test_set_name}' æˆ–æµ‹è¯•é›†ä¸ºç©º")
                return
            
            with st.spinner("A/Bæµ‹è¯•è¿è¡Œä¸­..."):
                # è¿è¡ŒåŸå§‹æç¤ºè¯æµ‹è¯•
                st.text("æµ‹è¯•åŸå§‹æç¤ºè¯...")
                original_results = run_test(
                    original_template, 
                    model, 
                    test_set, 
                    model_provider=model_provider,
                    repeat_count=repeat_count,
                    temperature=temperature
                )
                
                # è¿è¡Œä¼˜åŒ–æç¤ºè¯æµ‹è¯•
                st.text("æµ‹è¯•ä¼˜åŒ–æç¤ºè¯...")
                optimized_results = run_test(
                    optimized_template, 
                    model, 
                    test_set,
                    model_provider=model_provider,
                    repeat_count=repeat_count,
                    temperature=temperature
                )
                
                # ä¿å­˜ç»“æœ
                st.session_state.ab_test_results = {
                    "original": original_results,
                    "optimized": optimized_results,
                    "params": {
                        "repeat_count": repeat_count,
                        "temperature": temperature
                    }
                }
                
                # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºç»“æœ
                st.rerun()
    
    # å¦‚æœå·²æœ‰æµ‹è¯•ç»“æœï¼Œæ˜¾ç¤ºç»“æœ
    if "ab_test_results" in st.session_state:
        display_ab_test_results(st.session_state.ab_test_results)
        
        # æ·»åŠ æ¸…é™¤ç»“æœæŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…é™¤æµ‹è¯•ç»“æœ", key="clear_ab_results"):
            if "ab_test_results" in st.session_state:
                del st.session_state.ab_test_results
            st.rerun()

def display_ab_test_results(ab_results):
    """æ˜¾ç¤ºA/Bæµ‹è¯•ç»“æœå¯¹æ¯”"""
    st.subheader("A/Bæµ‹è¯•ç»“æœ")
    
    original_results = ab_results["original"]
    optimized_results = ab_results["optimized"]
    params = ab_results.get("params", {})
    
    # è·å–æ¨¡å‹ä¿¡æ¯
    model = original_results.get("model", "æœªçŸ¥æ¨¡å‹")
    model_provider = original_results.get("model_provider", "æœªçŸ¥æä¾›å•†")
    
    # æ˜¾ç¤ºæµ‹è¯•å‚æ•°
    st.info(f"""
    **æµ‹è¯•ä¿¡æ¯**:
    - æµ‹è¯•æ¨¡å‹: **{model}** (æä¾›å•†: **{model_provider}**)
    - æ¯ä¸ªæµ‹è¯•é‡å¤æ¬¡æ•°: **{params.get('repeat_count', 1)}**
    - æ¸©åº¦è®¾ç½®: **{params.get('temperature', 0.7)}**
    """)
    
    # è®¡ç®—å¹³å‡åˆ†æ•°
    original_avg = calculate_average_score(original_results)
    optimized_avg = calculate_average_score(optimized_results)
    
    # æ˜¾ç¤ºæ€»ä½“å¯¹æ¯”
    st.subheader("æ€»ä½“æ€§èƒ½å¯¹æ¯”")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("åŸå§‹æç¤ºè¯å¹³å‡åˆ†", f"{original_avg:.1f}")
    
    with col2:
        st.metric("ä¼˜åŒ–æç¤ºè¯å¹³å‡åˆ†", f"{optimized_avg:.1f}")
    
    with col3:
        improvement = ((optimized_avg - original_avg) / original_avg * 100) if original_avg > 0 else 0
        st.metric("æ”¹è¿›", f"{improvement:.1f}%", delta=f"{improvement:.1f}%")
    
    # è·å–ç»´åº¦è¯„åˆ†
    original_dims = get_dimension_scores(original_results)
    optimized_dims = get_dimension_scores(optimized_results)
    
    # ç»´åº¦å¯¹æ¯”ä¸æ”¹è¿›è¡¨æ ¼
    compare_dimension_performance([original_results, optimized_results], ["åŸå§‹æç¤ºè¯", "ä¼˜åŒ–æç¤ºè¯"])
    
    # æ˜¾ç¤ºç”¨ä¾‹çº§æ¯”è¾ƒ
    st.subheader("ç”¨ä¾‹çº§æ¯”è¾ƒ")
    
    for case_index in range(min(len(original_results.get("test_cases", [])), len(optimized_results.get("test_cases", [])))):
        original_case = original_results["test_cases"][case_index]
        optimized_case = optimized_results["test_cases"][case_index]
        
        # è®¡ç®—ç”¨ä¾‹å¾—åˆ†
        original_case_score = calculate_case_score(original_case)
        optimized_case_score = calculate_case_score(optimized_case)
        
        # è®¡ç®—æ”¹è¿›
        case_improvement = ((optimized_case_score - original_case_score) / original_case_score * 100) if original_case_score > 0 else 0
        
        # ç¡®å®šå“ªä¸ªæ›´å¥½
        better_version = "ä¼˜åŒ–ç‰ˆæœ¬" if optimized_case_score > original_case_score else "åŸå§‹ç‰ˆæœ¬" if original_case_score > optimized_case_score else "ç›¸åŒ"
        
        with st.expander(f"ç”¨ä¾‹ {case_index+1}: {original_case.get('case_description', original_case.get('case_id', ''))} ({better_version}æ›´å¥½)"):
            # æ˜¾ç¤ºç”¨ä¾‹ä¿¡æ¯
            display_test_case_details(original_case, show_system_prompt=False)
            
            # æ˜¾ç¤ºç”¨ä¾‹æ¯”è¾ƒ
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("åŸå§‹æç¤ºè¯å“åº”")
                st.code(original_case.get("prompt", ""))
                display_response_tabs(original_case.get("responses", []))
            
            with col2:
                st.subheader("ä¼˜åŒ–æç¤ºè¯å“åº”")
                st.code(optimized_case.get("prompt", ""))
                display_response_tabs(optimized_case.get("responses", []))
    
    # ç»“è®º
    st.subheader("ç»“è®º")
    
    if optimized_avg > original_avg:
        st.success(f"âœ… ä¼˜åŒ–æç¤ºè¯æ•´ä½“è¡¨ç°æ›´å¥½ï¼Œæå‡äº† {improvement:.1f}%")
        
        # æ‰¾å‡ºæœ€å¤§æ”¹è¿›çš„ç»´åº¦
        if improvements:
            best_dim = max(improvements.items(), key=lambda x: x[1])
            st.write(f"æœ€å¤§æ”¹è¿›åœ¨ **{best_dim[0]}** ç»´åº¦ï¼Œæå‡äº† **{best_dim[1]:.1f}%**")
        
        # ä¿å­˜ä¼˜åŒ–æç¤ºè¯
        if st.button("ä¿å­˜ä¼˜åŒ–æç¤ºè¯ä¸ºæ¨¡æ¿", type="primary"):
            optimized_template = st.session_state.ab_test_optimized
            new_template = dict(optimized_template)
            new_name = save_optimized_template(new_template, {"prompt": new_template.get("template", ""), "strategy": new_template.get("description", "")})
            st.success(f"å·²å°†ä¼˜åŒ–æç¤ºè¯ä¿å­˜ä¸ºæ–°æ¨¡æ¿: {new_name}")
    
    elif optimized_avg < original_avg:
        st.error(f"âŒ ä¼˜åŒ–æç¤ºè¯æ•´ä½“è¡¨ç°ä¸å¦‚åŸå§‹æç¤ºè¯ï¼Œä¸‹é™äº† {abs(improvement):.1f}%")
        st.write("å»ºè®®é‡æ–°ä¼˜åŒ–æç¤ºè¯æˆ–ä¿ç•™åŸå§‹æç¤ºè¯")
    else:
        st.info("ğŸ”„ ä¼˜åŒ–æç¤ºè¯å’ŒåŸå§‹æç¤ºè¯è¡¨ç°ç›¸å½“")

def calculate_case_score(case):
    """è®¡ç®—å•ä¸ªæµ‹è¯•ç”¨ä¾‹çš„å¹³å‡å¾—åˆ†"""
    total_score = 0
    count = 0
    
    responses = case.get("responses", [])
    for resp in responses:
        eval_result = resp.get("evaluation")
        if eval_result and "overall_score" in eval_result:
            total_score += eval_result["overall_score"]
            count += 1
    
    return total_score / count if count > 0 else 0
